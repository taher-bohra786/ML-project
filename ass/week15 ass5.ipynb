{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** Elastic Net Regression is a linear regression model that combines L1 (Lasso) and L2 (Ridge) penalties to balance feature selection and regularization. It differs by addressing multicollinearity and selecting correlated features.  \n",
    "\n",
    "**Q2:** Use cross-validation (e.g., GridSearchCV or RandomizedSearchCV) to find optimal values for the regularization parameters (alpha and l1_ratio).  \n",
    "\n",
    "**Q3:**  \n",
    "**Advantages:** Handles multicollinearity, performs feature selection, and prevents overfitting.  \n",
    "**Disadvantages:** Requires tuning hyperparameters and may be computationally expensive.  \n",
    "\n",
    "**Q4:** Used in high-dimensional datasets, genetics, finance, and text classification for feature selection and regularization.  \n",
    "\n",
    "**Q5:** Coefficients represent the influence of features on the target variable, with some shrunk to zero (feature selection).  \n",
    "\n",
    "**Q6:** Use imputation techniques like mean/median imputation or sklearnâ€™s `SimpleImputer` before fitting the model.  \n",
    "\n",
    "**Q7:** Features with zero coefficients are irrelevant and can be removed, making it useful for feature selection.  \n",
    "\n",
    "**Q8:** Use `pickle` or `joblib`:  \n",
    "- **Pickle model:** `pickle.dump(model, open('model.pkl', 'wb'))`  \n",
    "- **Unpickle model:** `model = pickle.load(open('model.pkl', 'rb'))`  \n",
    "\n",
    "**Q9:** Pickling saves the trained model for later use, allowing efficient reuse without retraining."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
